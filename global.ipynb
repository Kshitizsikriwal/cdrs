{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf71799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Starting dynamic extraction...\n",
      "‚úÖ Successfully extracted data from /Users/kshitizsikriwal/Kshitiz/evaluation-2025/Gemini/compilance-asthma.ipynb\n",
      "‚úÖ Successfully extracted data from /Users/kshitizsikriwal/Kshitiz/evaluation-2025/Gemini/compilance-diabetes.ipynb\n",
      "‚úÖ Successfully extracted data from /Users/kshitizsikriwal/Kshitiz/evaluation-2025/Gemini/compilance-cholesterol.ipynb\n",
      "‚úÖ Successfully extracted data from /Users/kshitizsikriwal/Kshitiz/evaluation-2025/GPT/compilance-asthma.ipynb\n",
      "‚úÖ Successfully extracted data from /Users/kshitizsikriwal/Kshitiz/evaluation-2025/GPT/compilance-diabetes.ipynb\n",
      "‚úÖ Successfully extracted data from /Users/kshitizsikriwal/Kshitiz/evaluation-2025/GPT/compilance-cholesterol.ipynb\n",
      "\n",
      "üìä Consolidated Data:\n",
      "    Model      Disease    Plan  Unnamed:_0  Strict_Compliance_%  \\\n",
      "0   Users       Asthma  Plan A           0            88.570000   \n",
      "1   Users       Asthma  Plan B           1            81.430000   \n",
      "2   Users     Diabetes  Plan A           0            95.714286   \n",
      "3   Users     Diabetes  Plan B           1            92.857143   \n",
      "4   Users  Cholesterol  Plan A           0            84.762857   \n",
      "5   Users  Cholesterol  Plan B           1            81.904286   \n",
      "6   Users       Asthma  Plan A           0            75.714286   \n",
      "7   Users       Asthma  Plan B           1            81.428571   \n",
      "8   Users     Diabetes  Plan A           0            78.571429   \n",
      "9   Users     Diabetes  Plan B           1            81.428571   \n",
      "10  Users  Cholesterol  Plan A           0           100.000000   \n",
      "11  Users  Cholesterol  Plan B           1           100.000000   \n",
      "\n",
      "    Partial_Compliance_%  \n",
      "0              94.290000  \n",
      "1              90.000000  \n",
      "2              95.714286  \n",
      "3              94.285714  \n",
      "4              85.715714  \n",
      "5              84.761429  \n",
      "6              88.571429  \n",
      "7              88.571429  \n",
      "8              84.285714  \n",
      "9              91.428571  \n",
      "10            100.000000  \n",
      "11            100.000000  \n",
      "\n",
      "üìÅ File saved successfully as: overall_compliance_from_both_models.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the paths to the notebooks\n",
    "file_paths = [\n",
    "    \"/Users/kshitizsikriwal/Kshitiz/evaluation-2025/Gemini/compilance-asthma.ipynb\",\n",
    "    \"/Users/kshitizsikriwal/Kshitiz/evaluation-2025/Gemini/compilance-diabetes.ipynb\",\n",
    "    \"/Users/kshitizsikriwal/Kshitiz/evaluation-2025/Gemini/compilance-cholesterol.ipynb\",\n",
    "    \"/Users/kshitizsikriwal/Kshitiz/evaluation-2025/GPT/compilance-asthma.ipynb\",\n",
    "    \"/Users/kshitizsikriwal/Kshitiz/evaluation-2025/GPT/compilance-diabetes.ipynb\",\n",
    "    \"/Users/kshitizsikriwal/Kshitiz/evaluation-2025/GPT/compilance-cholesterol.ipynb\"\n",
    "]\n",
    "\n",
    "def extract_table_from_notebook(file_path):\n",
    "    \"\"\"\n",
    "    Parses a Jupyter notebook to find the 'Average compliance' table \n",
    "    and returns it as a DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            nb_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ö†Ô∏è File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    # Determine Model and Disease from file path\n",
    "    path_parts = file_path.split('/')\n",
    "    model = path_parts[1]  # 'Gemini' or 'GPT'\n",
    "    # Extract disease from filename (e.g., 'compilance-asthma.ipynb' -> 'Asthma')\n",
    "    filename = path_parts[-1]\n",
    "    disease = filename.replace('compilance-', '').replace('.ipynb', '').capitalize()\n",
    "\n",
    "    for cell in nb_data.get('cells', []):\n",
    "        if cell.get('cell_type') == 'code':\n",
    "            outputs = cell.get('outputs', [])\n",
    "            \n",
    "            # Check if this cell contains the target output\n",
    "            has_summary_text = False\n",
    "            html_content = None\n",
    "            \n",
    "            for output in outputs:\n",
    "                # Check for the specific print statement indicating the summary table\n",
    "                if output.get('output_type') == 'stream':\n",
    "                    text = \"\".join(output.get('text', []))\n",
    "                    if \"Average compliance\" in text:\n",
    "                        has_summary_text = True\n",
    "                \n",
    "                # Capture the HTML table data if present\n",
    "                if output.get('output_type') in ['display_data', 'execute_result']:\n",
    "                    data = output.get('data', {})\n",
    "                    if 'text/html' in data:\n",
    "                        html_content = \"\".join(data['text/html'])\n",
    "\n",
    "            # If we found the text marker and have HTML content, parse it\n",
    "            if has_summary_text and html_content:\n",
    "                try:\n",
    "                    # Parse HTML table into DataFrame\n",
    "                    df = pd.read_html(StringIO(html_content))[0]\n",
    "                    \n",
    "                    # Normalize column names\n",
    "                    df.columns = [c.replace(' ', '_').replace('(', '').replace(')', '') for c in df.columns]\n",
    "                    \n",
    "                    # Add metadata columns\n",
    "                    df['Model'] = model\n",
    "                    df['Disease'] = disease\n",
    "                    \n",
    "                    # Select and rename relevant columns to ensure consistency\n",
    "                    # Note: Handling potential slight variations in column names across files\n",
    "                    rename_map = {\n",
    "                        'meal_plan': 'Plan',\n",
    "                        'Avg_Strict_Compliance%': 'Strict_Compliance_%',\n",
    "                        'Avg_Partial_Compliance%': 'Partial_Compliance_%'\n",
    "                    }\n",
    "                    df = df.rename(columns=rename_map)\n",
    "                    \n",
    "                    # Reorder for readability\n",
    "                    cols = ['Model', 'Disease', 'Plan'] + [c for c in df.columns if c not in ['Model', 'Disease', 'Plan']]\n",
    "                    return df[cols]\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing table in {file_path}: {e}\")\n",
    "\n",
    "    print(f\"‚ö†Ô∏è No summary table found in {file_path}\")\n",
    "    return None\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "all_data = []\n",
    "\n",
    "print(\"üîÑ Starting dynamic extraction...\")\n",
    "\n",
    "for path in file_paths:\n",
    "    df_result = extract_table_from_notebook(path)\n",
    "    if df_result is not None:\n",
    "        all_data.append(df_result)\n",
    "        print(f\"‚úÖ Successfully extracted data from {path}\")\n",
    "\n",
    "if all_data:\n",
    "    # Combine all extracted dataframes\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_filename = \"overall_compliance_from_both_models.csv\"\n",
    "    final_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(\"\\nüìä Consolidated Data:\")\n",
    "    print(final_df)\n",
    "    print(f\"\\nüìÅ File saved successfully as: {output_filename}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No data could be extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf1a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import io\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List of all notebook paths to process\n",
    "file_paths = [\n",
    "    \"/Users/kshitizsikriwal/Kshitiz/evaluation-2025/Gemini/compilance-asthma.ipynb\",\n",
    "    \"/Users/kshitizsikriwal/Kshitiz/evaluation-2025/Gemini/compilance-diabetes.ipynb\",\n",
    "    \"/Users/kshitizsikriwal/Kshitiz/evaluation-2025/Gemini/compilance-cholesterol.ipynb\",\n",
    "    \"/Users/kshitizsikriwal/Kshitiz/evaluation-2025/GPT/compilance-asthma.ipynb\",\n",
    "    \"/Users/kshitizsikriwal/Kshitiz/evaluation-2025/GPT/compilance-diabetes.ipynb\",\n",
    "    \"/Users/kshitizsikriwal/Kshitiz/evaluation-2025/GPT/compilance-cholesterol.ipynb\"\n",
    "]\n",
    "\n",
    "def extract_compliance_data(file_path):\n",
    "    \"\"\"\n",
    "    Reads a notebook, finds the 'Average compliance' table, \n",
    "    and returns a DataFrame with Model, Disease, Plan, and Compliance scores.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            notebook = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ö†Ô∏è File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    # Identify Model and Disease from the file path\n",
    "    # Assumes structure: evaluation-2025/ModelName/filename.ipynb\n",
    "    path_parts = file_path.split('/')\n",
    "    model_name = path_parts[1]  # 'Gemini' or 'GPT'\n",
    "    disease_name = path_parts[-1].replace('compilance-', '').replace('.ipynb', '').capitalize()\n",
    "\n",
    "    for cell in notebook.get('cells', []):\n",
    "        # We only care about code cells with outputs\n",
    "        if cell.get('cell_type') == 'code':\n",
    "            outputs = cell.get('outputs', [])\n",
    "            for output in outputs:\n",
    "                # Check if this output contains our target HTML table\n",
    "                # We look for specific column headers usually found in the HTML\n",
    "                if 'data' in output and 'text/html' in output['data']:\n",
    "                    html_content = \"\".join(output['data']['text/html'])\n",
    "                    \n",
    "                    # Quick check if this is the right table\n",
    "                    if \"Avg_Strict_Compliance\" in html_content or \"strict_compliance_%\" in html_content:\n",
    "                        try:\n",
    "                            # Parse the HTML table\n",
    "                            df = pd.read_html(io.StringIO(html_content))[0]\n",
    "                            \n",
    "                            # Normalize Column Names (remove %, (), spaces)\n",
    "                            # Expected original: meal_plan, Avg_Strict_Compliance(%), Avg_Partial_Compliance(%)\n",
    "                            df.columns = [\n",
    "                                c.replace(' ', '_')\n",
    "                                 .replace('(', '')\n",
    "                                 .replace(')', '')\n",
    "                                 .replace('%', '')\n",
    "                                 .replace('Avg_', '') # Standardize naming\n",
    "                                 .strip() \n",
    "                                for c in df.columns\n",
    "                            ]\n",
    "                            \n",
    "                            # Standardize specific column names to a common format\n",
    "                            # We want: Plan, Strict, Partial\n",
    "                            rename_map = {}\n",
    "                            for col in df.columns:\n",
    "                                if 'meal_plan' in col.lower() or 'plan' in col.lower():\n",
    "                                    rename_map[col] = 'Plan'\n",
    "                                elif 'strict' in col.lower():\n",
    "                                    rename_map[col] = 'Strict_Compliance'\n",
    "                                elif 'partial' in col.lower():\n",
    "                                    rename_map[col] = 'Partial_Compliance'\n",
    "                            \n",
    "                            df = df.rename(columns=rename_map)\n",
    "                            \n",
    "                            # Filter only necessary columns if table is larger\n",
    "                            if 'Plan' in df.columns and 'Strict_Compliance' in df.columns:\n",
    "                                df['Model'] = model_name\n",
    "                                df['Disease'] = disease_name\n",
    "                                return df[['Model', 'Disease', 'Plan', 'Strict_Compliance', 'Partial_Compliance']]\n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            pass # Continue looking if parsing fails\n",
    "    return None\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "all_dataframes = []\n",
    "\n",
    "print(\"üîÑ Processing files...\")\n",
    "for path in file_paths:\n",
    "    df = extract_compliance_data(path)\n",
    "    if df is not None:\n",
    "        all_dataframes.append(df)\n",
    "        print(f\"‚úÖ Extracted: {path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to extract: {path}\")\n",
    "\n",
    "if all_dataframes:\n",
    "    # 1. Combine all raw data\n",
    "    full_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # 2. Group by Model and Plan to get the Mean (Average) across all diseases\n",
    "    final_aggregation = full_df.groupby(['Model', 'Plan'])[['Strict_Compliance', 'Partial_Compliance']].mean().reset_index()\n",
    "    \n",
    "    # Formatting for cleaner display (round to 2 decimal places)\n",
    "    final_aggregation['Strict_Compliance'] = final_aggregation['Strict_Compliance'].round(2)\n",
    "    final_aggregation['Partial_Compliance'] = final_aggregation['Partial_Compliance'].round(2)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä FINAL AGGREGATED RESULTS (Average across Asthma, Diabetes, Cholesterol)\")\n",
    "    print(\"=\"*60)\n",
    "    print(final_aggregation.to_string(index=False))\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 3. Save to CSV\n",
    "    output_file = \"overall_compliance_summary.csv\"\n",
    "    final_aggregation.to_csv(output_file, index=False)\n",
    "    print(f\"\\nüìÅ Final aggregated file saved as: {output_file}\")\n",
    "\n",
    "else:\n",
    "    print(\"No data found to aggregate.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
